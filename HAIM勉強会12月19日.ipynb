{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAIM勉強会12月19日",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM9esJ9/hh4sg2XOOJv5tyC",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydaigo/The-4th-Tellus-Satellite-Challenge/blob/main/HAIM%E5%8B%89%E5%BC%B7%E4%BC%9A12%E6%9C%8819%E6%97%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLI3buKfdG0L"
      },
      "source": [
        "#HAIM勉強会12月19日\n",
        "#海岸線抽出コンペ奮闘記\n",
        "\n",
        "#自己紹介\n",
        "\n",
        "- twitter abcd161  \n",
        "- 住んでいる所　富山  \n",
        "- 目標　kaggleでExpertになること\n",
        "\n",
        "- signateでの実績\n",
        "  - [国立国会図書館の画像データレイアウト認識](https://signate.jp/competitions/218) 14/101\n",
        "  - [The 4th Tellus Satellite Challenge：海岸線の抽出](https://signate.jp/competitions/284) 22/125　今回のLTでプレゼン\n",
        "\n",
        "![](https://i.imgur.com/UW28ZLP.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl6i3zzsbbrN"
      },
      "source": [
        "# 海岸線の抽出コンペ概要\r\n",
        "\r\n",
        "- 内容\r\n",
        "  - 海岸の衛星データから海と陸の境界である海岸線を抽出精度を競う。\r\n",
        "  ![](https://i.imgur.com/7dmXLD9.png)\r\n",
        "- 社会的意義\r\n",
        "  - 海岸の浸食されることで動植物への影響や高潮や津波を防ぐ能力が弱くなることが問題となっている。\r\n",
        "  - 衛星から海岸を監視することで海岸の浸食をいち早く察知する取り組みがある。\r\n",
        "  - 衛星の画像から海岸領域を判読するのに高度なスキルが必要である。  \r\n",
        "↓  \r\n",
        "高い精度で海岸線を抽出するアルゴリズムが必要！\r\n",
        "\r\n",
        "- 結果\r\n",
        "  - サブミットとスコアの推移\r\n",
        "\r\n",
        "![](https://i.imgur.com/9GtnhQF.png)\r\n",
        "\r\n",
        "\r\n",
        "# コンペの流れ\r\n",
        "\r\n",
        "![](https://i.imgur.com/nofA3zy.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrfCY-jVbwlk"
      },
      "source": [
        "# 奮闘記\r\n",
        "\r\n",
        "本コンペでの自分の取り組みを説明\r\n",
        "\r\n",
        "- 第1話: 評価指標を見てみる\r\n",
        "\r\n",
        "- 第2話: サンプル用の提出データをとりあえず提出する\r\n",
        "\r\n",
        "- 第3話 データを見る\r\n",
        "\r\n",
        "- 第4話: kaggleで似たコンペがないかを探す\r\n",
        "\r\n",
        "- 第5話: Unetとは?\r\n",
        "\r\n",
        "- 第6話: 入力画像を大きくする→成功\r\n",
        "\r\n",
        "- 第7話: モデルを深くする→失敗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2int37dhm-K"
      },
      "source": [
        "# 第1話　評価指標を見る\r\n",
        "- 実際の海岸線に垂直にひかれた評価選を用いて、予測した海岸線と実際の海岸線との誤差をスコアとして算出する。\r\n",
        "\r\n",
        "- 評価線一つあたりの誤差が評価指標となる。\r\n",
        "\r\n",
        "- 評価線の長さは165ピクセルであるため、165が最低スコアである\r\n",
        "\r\n",
        "- 誤差が小さいほど検出精度が高いことになる。\r\n",
        "\r\n",
        "\r\n",
        "<img src=\"https://static.signate.jp/competitions/284/RsCDYrykZ4dblRI8WQQltbAgyWRFs6nu3laR3llE.png\" width=\"60%\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS8EGgTJFxQm"
      },
      "source": [
        "#第2話サンプル用の提出データをとりあえず提出する\r\n",
        "\r\n",
        "- サンプル用の提出データは左上から右下に海岸線があるとすべて予測されている\r\n",
        "\r\n",
        "![](https://i.imgur.com/PPGzvFa.png)\r\n",
        "\r\n",
        "\r\n",
        "![](https://i.imgur.com/iweXCHR.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giwTkfItZYhZ"
      },
      "source": [
        "# 第3話 データを見る\r\n",
        "- 訓練用の海岸線の画像が20枚とそれらに対応する海岸線の位置を表したjsonファイルとテスト用の海岸の画像が30枚与えられる。\r\n",
        "  - 時間帯の違う同じ場所の画像がありデータが欠損している\r\n",
        "\r\n",
        "  ![](https://i.imgur.com/9VDH7Dx.png)\r\n",
        "  - 画像サイズが大きい\r\n",
        "  \r\n",
        "  ![](https://i.imgur.com/DoOsqSh.png)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIIfiEL5n3oX"
      },
      "source": [
        "# 第4話　kaggleで似たコンペがないかを探す\r\n",
        "\r\n",
        "- [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge)という地質画像から塩領域を特定するコンテストが見つかった\r\n",
        "  - コンペの内容はする塩領域とそうでない領域をピクセル単位で分類\r\n",
        "  - 緑が塩がない領域またはすべてが塩の領域、赤が塩がある領域\r\n",
        "\r\n",
        "![](https://i.imgur.com/KzPpwoz.png)\r\n",
        "[出典](https://arxiv.org/pdf/1904.04445.pdf)\r\n",
        "\r\n",
        "- このコンペの[Notebooks](https://www.kaggle.com/jesperdramsch/intro-to-seismic-salt-and-how-to-geophysics)を参考にコードを書くことにした\r\n",
        "  - 塩領域の分類をUnetというアルゴリズムを用いて実現している\r\n",
        "  - kerasを用いてUnetを実装している"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5BITAOL2E3C"
      },
      "source": [
        "# 第5話 Unetとは?\r\n",
        "\r\n",
        "- セマンティックセグメンテーションのアルゴリズムの一つ\r\n",
        "- \r\n",
        "- セマンティックセグメンテーションとは画像に写っている物体をピクセルレベルで識別する技術  \r\n",
        "セマンティックセグメンテーションの例  \r\n",
        "![](https://raw.githubusercontent.com/open-mmlab/mmdetection/master/resources/coco_test_12510.jpg)\r\n",
        "\r\n",
        "- Unetのアーキテクチャー\r\n",
        "\r\n",
        "![](https://www.acceluniverse.com/blog/developers/u_net_arc2.png)\r\n",
        "\r\n",
        "- 特徴\r\n",
        "  - 学習が速い\r\n",
        "  - 少ないデータで学習ができる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmj75VazUq5"
      },
      "source": [
        "#第3話 境界線を予測するモデルを作る→失敗\r\n",
        "\r\n",
        "- Unetのモデルを入力画像を海岸の画像、出力画像を海岸線の画像として学習させた  \r\n",
        "↓   \r\n",
        "##失敗\r\n",
        "\r\n",
        "![](https://i.imgur.com/gyZwaQ4.png)\r\n",
        "\r\n",
        "\r\n",
        "- 理由\r\n",
        "  - 正解ラベルの数が少なすぎて、適切にモデルをとレーニングができなかったため。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwq0Xt7FrP1l"
      },
      "source": [
        "# 第5話セマンティックセグメンテーション用にラベルを付けなおして再学習！\r\n",
        "\r\n",
        "- 手動でマスク画像を作成し直す\r\n",
        "- 画像サイズは128*128\r\n",
        "\r\n",
        "![](https://i.imgur.com/ZmIyFLQ.png)\r\n",
        "\r\n",
        "![Uploading file..._gptip3pzt]()\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bP-xKRxAs9C"
      },
      "source": [
        "#第6話データを拡張してみる\r\n",
        "- 欠損データに対応するためにデータの拡張により疑似的にデータが欠損した部分を作成する。\r\n",
        "\r\n",
        "![](https://i.imgur.com/KH7KPjz.png)\r\n",
        "\r\n",
        "![](https://i.imgur.com/55Va3DS.png)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dcq-bHxBE87"
      },
      "source": [
        "# 第7話 入力サイズを大きくする\r\n",
        "- 入力画像サイズを128＊128から512＊512とした\r\n",
        "\r\n",
        "![](https://i.imgur.com/152bh0w.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC3lJNJrBZxV"
      },
      "source": [
        "#最終話　結果\r\n",
        "###シェイクアップ!!\r\n",
        "- 暫定スコア 30  \r\n",
        "↓\r\n",
        "- 最終スコア 18  \r\n",
        "\r\n",
        "#結果22位となった！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTaq2H5T3lPo"
      },
      "source": [
        "# ハンズオン\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rMilMvOI3oFr",
        "outputId": "0078faf7-f36b-4e82-9fc5-5850c909f3a9"
      },
      "source": [
        "#@title ライブラリのインポート\r\n",
        "!git clone https://github.com/ydaigo/The-4th-Tellus-Satellite-Challenge.git\r\n",
        "!pip uninstall tensorflow -y\r\n",
        "!pip install tensorflow-gpu==1.15\r\n",
        "!pip uninstall keras -y\r\n",
        "!pip install keras==2.2.4\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import json\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import cv2\r\n",
        "import tifffile\r\n",
        "from tqdm import tqdm_notebook, tnrange\r\n",
        "from itertools import chain\r\n",
        "from skimage.io import imread, imshow, concatenate_images\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.morphology import label\r\n",
        "\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\r\n",
        "from keras.layers.pooling import MaxPooling2D\r\n",
        "from keras.layers.merge import concatenate\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'The-4th-Tellus-Satellite-Challenge'...\n",
            "remote: Enumerating objects: 28, done.\u001b[K\n",
            "remote: Counting objects: 100% (28/28), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 28 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (28/28), done.\n",
            "Uninstalling tensorflow-2.4.0:\n",
            "  Successfully uninstalled tensorflow-2.4.0\n",
            "Collecting tensorflow-gpu==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a5/ad/933140e74973fb917a194ab814785e7c23680ca5dee6d663a509fe9579b6/tensorflow_gpu-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (411.5MB)\n",
            "\u001b[K     |████████████████████████████████| 411.5MB 44kB/s \n",
            "\u001b[?25hRequirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.8.1)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.19.4)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.12.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.12.4)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.15.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.36.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 51.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.10.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.32.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (0.2.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 9.1MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 50.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==1.15) (50.3.2)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.3)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow-gpu==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=b1cc511dbb05f5754b6714b474dd38afedcf7132018d1482ef6552f4bf2ee07f\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.11.0 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorboard, keras-applications, tensorflow-estimator, tensorflow-gpu\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorboard 2.4.0\n",
            "    Uninstalling tensorboard-2.4.0:\n",
            "      Successfully uninstalled tensorboard-2.4.0\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-estimator-1.15.1 tensorflow-gpu-1.15.0\n",
            "Uninstalling Keras-2.4.3:\n",
            "  Successfully uninstalled Keras-2.4.3\n",
            "Collecting keras==2.2.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5e/10/aa32dad071ce52b5502266b5c659451cfd6ffcbf14e6c8c4f16c0ff5aaab/Keras-2.2.4-py2.py3-none-any.whl (312kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.0.8)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.15.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (2.10.0)\n",
            "Requirement already satisfied: scipy>=0.14 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.19.4)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (3.13)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from keras==2.2.4) (1.1.2)\n",
            "\u001b[31mERROR: fancyimpute 0.4.3 requires tensorflow, which is not installed.\u001b[0m\n",
            "Installing collected packages: keras\n",
            "Successfully installed keras-2.2.4\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-cbfd06ad3ace>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0mmask_datagen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mdata_gen_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m \u001b[0mimage_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     62\u001b[0m \u001b[0mmask_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maugment\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0mimage_generator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_datagen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m17\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_to_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_prefix\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X_train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7VEmHyJ5IbE",
        "outputId": "e182c14a-6057-4cff-b086-59b44355410c"
      },
      "source": [
        "#@title 前処理\r\n",
        "im_width = 512\r\n",
        "im_height = 512\r\n",
        "im_chan = 1\r\n",
        "train_ids = [1,2]\r\n",
        "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\r\n",
        "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\r\n",
        "print('Getting and resizing train images and masks ... ')\r\n",
        "sys.stdout.flush()\r\n",
        "\r\n",
        "sizes_train = []\r\n",
        "for n,id_ in enumerate(train_ids):\r\n",
        "    img = load_img(f'/content/The-4th-Tellus-Satellite-Challenge/data/train_gray_{id_:02d}.png')\r\n",
        "    x = img_to_array(img)[:,:,1]\r\n",
        "    sizes_train.append([x.shape[0], x.shape[1]])\r\n",
        "    x = resize(x, (im_height, im_width, 1), mode='constant', preserve_range=True)\r\n",
        "    X_train[n] = x\r\n",
        "    mask = img_to_array(load_img(f'/content/The-4th-Tellus-Satellite-Challenge/data/train_mask_{id_:02d}.png'))[:,:,1]\r\n",
        "    mask = np.where(mask==255,0,255)\r\n",
        "    Y_train[n] = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Getting and resizing train images and masks ... \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVo2tzOHlcWH"
      },
      "source": [
        "#@title データの拡張\r\n",
        "data_gen_args  =dict(featurewise_center=False, \r\n",
        "                             samplewise_center=False, \r\n",
        "                             featurewise_std_normalization=False,\r\n",
        "                             samplewise_std_normalization=False, \r\n",
        "                             zca_whitening=False, \r\n",
        "                             zca_epsilon=1e-06, \r\n",
        "                             rotation_range=90, \r\n",
        "                             width_shift_range=0.1, \r\n",
        "                             height_shift_range=0.1,\r\n",
        "                             brightness_range=None,\r\n",
        "                             shear_range=90, zoom_range=0.0,\r\n",
        "                             channel_shift_range=0.0,\r\n",
        "                             fill_mode='constant', cval=0.0,\r\n",
        "                             horizontal_flip=True, \r\n",
        "                             vertical_flip=True, \r\n",
        "                             rescale=None, \r\n",
        "                             preprocessing_function=None, \r\n",
        "                             data_format=None,\r\n",
        "                             validation_split=0.0)\r\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\r\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\r\n",
        "seed = 1\r\n",
        "image_datagen.fit(X_train, augment=True, seed=seed)\r\n",
        "mask_datagen.fit(Y_train, augment=True, seed=seed)\r\n",
        "image_generator = image_datagen.flow(X_train[:17], y=None, batch_size=32, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\r\n",
        "mask_generator = mask_datagen.flow(Y_train[:17], y=None, batch_size=32, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\r\n",
        "train_generator = zip(image_generator, mask_generator)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "id": "UuwekTAc5T5K",
        "outputId": "8705ffc2-5c5d-4d61-e13d-f9ec2427d287"
      },
      "source": [
        "#@title モデル\r\n",
        "# Define IoU metric\r\n",
        "def mean_iou(y_true, y_pred):\r\n",
        "    prec = []\r\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\r\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\r\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\r\n",
        "        K.get_session().run(tf.local_variables_initializer())\r\n",
        "        with tf.control_dependencies([up_opt]):\r\n",
        "            score = tf.identity(score)\r\n",
        "        prec.append(score)\r\n",
        "    return K.mean(K.stack(prec), axis=0)\r\n",
        "# Build U-Net model\r\n",
        "inputs = Input((im_height, im_width, im_chan))\r\n",
        "s = Lambda(lambda x: x / 255) (inputs)\r\n",
        "\r\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\r\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\r\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\r\n",
        "\r\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\r\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\r\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\r\n",
        "\r\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\r\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\r\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\r\n",
        "\r\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\r\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\r\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\r\n",
        "\r\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\r\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\r\n",
        "\r\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\r\n",
        "u6 = concatenate([u6, c4])\r\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\r\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\r\n",
        "\r\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\r\n",
        "u7 = concatenate([u7, c3])\r\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\r\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\r\n",
        "\r\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\r\n",
        "u8 = concatenate([u8, c2])\r\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\r\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\r\n",
        "\r\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\r\n",
        "u9 = concatenate([u9, c1], axis=3)\r\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\r\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\r\n",
        "\r\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\r\n",
        "\r\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\r\n",
        "model.summary()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "WARNING:tensorflow:From <ipython-input-3-c69b4ab31881>:6: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.cast` instead.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/metrics_impl.py:1178: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Deprecated in favor of operator or tf.math.divide.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:186: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            (None, 512, 512, 1)  0                                            \n",
            "__________________________________________________________________________________________________\n",
            "lambda_1 (Lambda)               (None, 512, 512, 1)  0           input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 512, 512, 8)  80          lambda_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 512, 512, 8)  584         conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 8)  0           conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 256, 256, 16) 1168        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 256, 256, 16) 2320        conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 16) 0           conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 128, 128, 32) 4640        max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 128, 128, 32) 9248        conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 32)   0           conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 64, 64, 64)   18496       max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 64, 64, 64)   36928       conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 64)   0           conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 32, 32, 128)  73856       max_pooling2d_4[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 32, 32, 128)  147584      conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_1 (Conv2DTrans (None, 64, 64, 64)   32832       conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 64, 64, 128)  0           conv2d_transpose_1[0][0]         \n",
            "                                                                 conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 64, 64, 64)   73792       concatenate_1[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 64, 64, 64)   36928       conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_2 (Conv2DTrans (None, 128, 128, 32) 8224        conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_2 (Concatenate)     (None, 128, 128, 64) 0           conv2d_transpose_2[0][0]         \n",
            "                                                                 conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 128, 128, 32) 18464       concatenate_2[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 128, 128, 32) 9248        conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_3 (Conv2DTrans (None, 256, 256, 16) 2064        conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_3 (Concatenate)     (None, 256, 256, 32) 0           conv2d_transpose_3[0][0]         \n",
            "                                                                 conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 256, 256, 16) 4624        concatenate_3[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 256, 256, 16) 2320        conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_transpose_4 (Conv2DTrans (None, 512, 512, 8)  520         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_4 (Concatenate)     (None, 512, 512, 16) 0           conv2d_transpose_4[0][0]         \n",
            "                                                                 conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 512, 512, 8)  1160        concatenate_4[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 512, 512, 8)  584         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 512, 512, 1)  9           conv2d_18[0][0]                  \n",
            "==================================================================================================\n",
            "Total params: 485,673\n",
            "Trainable params: 485,673\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 379
        },
        "id": "zMTkHa3c5dQG",
        "outputId": "54850c53-d873-4135-bbae-a0c7352f8fdb"
      },
      "source": [
        "#title 学習\r\n",
        "import keras\r\n",
        "model = load_model('/content/The-4th-Tellus-Satellite-Challenge/34.h5', custom_objects={'mean_iou': mean_iou})\r\n",
        "class nvidia(keras.callbacks.Callback):\r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        !nvidia-smi\r\n",
        "earlystopper = EarlyStopping(patience=500, verbose=1)\r\n",
        "nvidiaCallback = nvidia()\r\n",
        "checkpointer = ModelCheckpoint('/content/model-tgs-salt-1.h5', verbose=1, save_best_only=True,monitor='val_mean_iou', mode='max')\r\n",
        "results = model.fit_generator(train_generator, validation_data=(X_train,Y_train), steps_per_epoch=300, epochs=300,\r\n",
        "                    callbacks=[earlystopper, checkpointer],shuffle=False)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "193/300 [==================>...........] - ETA: 14s - loss: 0.6144 - mean_iou: 0.3252"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-318a9f721592>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mcheckpointer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/model-tgs-salt-1.h5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'val_mean_iou'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'max'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m results = model.fit_generator(train_generator, validation_data=(X_train,Y_train), steps_per_epoch=300, epochs=300,\n\u001b[0;32m---> 11\u001b[0;31m                     callbacks=[earlystopper, checkpointer],shuffle=False)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1470\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1471\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1472\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE9Dqm1I6N1b",
        "outputId": "213d08dc-f671-4819-9f24-bcc2319e3a3b"
      },
      "source": [
        "#@title 予測\r\n",
        "model = load_model('/content/The-4th-Tellus-Satellite-Challenge/34.h5', custom_objects={'mean_iou': mean_iou})\r\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0])], verbose=1)\r\n",
        "\r\n",
        "# Threshold predictions\r\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\r2/2 [==============================] - 1s 281ms/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "Lp3Ay80K6SAB",
        "outputId": "2dbcfdb4-d66a-4ae4-be98-71d917b26979"
      },
      "source": [
        "# 予測結果の確認\r\n",
        "plt.imshow(np.squeeze(preds_train_t[0]))\r\n",
        "plt.show()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}