{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HAIM勉強会12月19日",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydaigo/The-4th-Tellus-Satellite-Challenge/blob/main/HAIM%E5%8B%89%E5%BC%B7%E4%BC%9A12%E6%9C%8819%E6%97%A5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rMilMvOI3oFr",
        "cellView": "form"
      },
      "source": [
        "#@title ライブラリのインポート\r\n",
        "!git clone https://github.com/ydaigo/The-4th-Tellus-Satellite-Challenge.git\r\n",
        "!pip uninstall tensorflow -y\r\n",
        "!pip install tensorflow-gpu==1.15\r\n",
        "!pip uninstall keras -y\r\n",
        "!pip install keras==2.2.4\r\n",
        "import os\r\n",
        "import sys\r\n",
        "import random\r\n",
        "import warnings\r\n",
        "import json\r\n",
        "\r\n",
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "%matplotlib inline\r\n",
        "\r\n",
        "import cv2\r\n",
        "import tifffile\r\n",
        "from tqdm import tqdm_notebook, tnrange\r\n",
        "from itertools import chain\r\n",
        "from skimage.io import imread, imshow, concatenate_images\r\n",
        "from skimage.transform import resize\r\n",
        "from skimage.morphology import label\r\n",
        "\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.layers import Input\r\n",
        "from keras.layers.core import Lambda\r\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\r\n",
        "from keras.layers.pooling import MaxPooling2D\r\n",
        "from keras.layers.merge import concatenate\r\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\r\n",
        "from keras import backend as K\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "\r\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLI3buKfdG0L"
      },
      "source": [
        "#HAIM勉強会12月19日\n",
        "#海岸線抽出コンペ奮闘記\n",
        "\n",
        "#自己紹介\n",
        "\n",
        "- twitter abcd161  \n",
        "- 住んでいる所　富山  \n",
        "- 目標　kaggleでExpertになること\n",
        "\n",
        "- signateでの実績\n",
        "  - [国立国会図書館の画像データレイアウト認識](https://signate.jp/competitions/218) 14/101\n",
        "  - [The 4th Tellus Satellite Challenge：海岸線の抽出](https://signate.jp/competitions/284) 22/125　今回のLTでプレゼン\n",
        "\n",
        "![](https://i.imgur.com/UW28ZLP.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gl6i3zzsbbrN"
      },
      "source": [
        "# 海岸線の抽出コンペ概要\r\n",
        "\r\n",
        "- 内容\r\n",
        "  - 海岸の衛星データから海と陸の境界である海岸線を抽出精度を競う。\r\n",
        "  ![](https://i.imgur.com/7dmXLD9.png)\r\n",
        "- 社会的意義\r\n",
        "  - 海岸の浸食されることで動植物への影響や高潮や津波を防ぐ能力が弱くなることが問題となっている。\r\n",
        "  - 衛星から海岸を監視することで海岸の浸食をいち早く察知する取り組みがある。\r\n",
        "  - 衛星の画像から海岸領域を判読するのに高度なスキルが必要である。  \r\n",
        "↓  \r\n",
        "高い精度で海岸線を抽出するアルゴリズムが必要！\r\n",
        "\r\n",
        "- 結果\r\n",
        "  - サブミットとスコアの推移\r\n",
        "\r\n",
        "![](https://i.imgur.com/9GtnhQF.png)\r\n",
        "\r\n",
        "\r\n",
        "# コンペの流れ\r\n",
        "\r\n",
        "![](https://i.imgur.com/nofA3zy.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrfCY-jVbwlk"
      },
      "source": [
        "# 奮闘記\r\n",
        "\r\n",
        "本コンペでの自分の取り組みを説明\r\n",
        "\r\n",
        "- 第1話: 評価指標を見てみる\r\n",
        "\r\n",
        "- 第2話: サンプル用の提出データをとりあえず提出する\r\n",
        "\r\n",
        "- 第3話 データを見る\r\n",
        "\r\n",
        "- 第4話: kaggleで似たコンペがないかを探す\r\n",
        "\r\n",
        "- 第5話: Unetとは?\r\n",
        "\r\n",
        "- 第6話: 入力画像を大きくする→成功\r\n",
        "\r\n",
        "- 第7話: モデルを深くする→失敗"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y2int37dhm-K"
      },
      "source": [
        "# 第1話　評価指標を見る\r\n",
        "- 実際の海岸線に垂直にひかれた評価選を用いて、予測した海岸線と実際の海岸線との誤差をスコアとして算出する。\r\n",
        "\r\n",
        "- 評価線一つあたりの誤差が評価指標となる。\r\n",
        "\r\n",
        "- 評価線の長さは165ピクセルであるため、165が最低スコアである\r\n",
        "\r\n",
        "- 誤差が小さいほど検出精度が高いことになる。\r\n",
        "\r\n",
        "\r\n",
        "<img src=\"https://static.signate.jp/competitions/284/RsCDYrykZ4dblRI8WQQltbAgyWRFs6nu3laR3llE.png\" width=\"60%\">\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uS8EGgTJFxQm"
      },
      "source": [
        "#第2話サンプル用の提出データをとりあえず提出する\r\n",
        "\r\n",
        "- サンプル用の提出データは左上から右下に海岸線があるとすべて予測されている\r\n",
        "\r\n",
        "![](https://i.imgur.com/PPGzvFa.png)\r\n",
        "\r\n",
        "\r\n",
        "![](https://i.imgur.com/iweXCHR.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giwTkfItZYhZ"
      },
      "source": [
        "# 第3話 データを見る\r\n",
        "- 訓練用の海岸線の画像が20枚とそれらに対応する海岸線の位置を表したjsonファイルとテスト用の海岸の画像が30枚与えられる。\r\n",
        "  - 時間帯の違う同じ場所の画像がありデータが欠損している\r\n",
        "\r\n",
        "  ![](https://i.imgur.com/9VDH7Dx.png)\r\n",
        "  - 画像サイズが大きい\r\n",
        "  \r\n",
        "  ![](https://i.imgur.com/DoOsqSh.png)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIIfiEL5n3oX"
      },
      "source": [
        "# 第4話　kaggleで似たコンペがないかを探す\r\n",
        "\r\n",
        "- [TGS Salt Identification Challenge](https://www.kaggle.com/c/tgs-salt-identification-challenge)という地質画像から塩領域を特定するコンテストが見つかった\r\n",
        "  - コンペの内容はする塩領域とそうでない領域をピクセル単位で分類\r\n",
        "  - 緑が塩がない領域またはすべてが塩の領域、赤が塩がある領域\r\n",
        "\r\n",
        "![](https://i.imgur.com/KzPpwoz.png)\r\n",
        "[出典](https://arxiv.org/pdf/1904.04445.pdf)\r\n",
        "\r\n",
        "- このコンペの[Notebooks](https://www.kaggle.com/jesperdramsch/intro-to-seismic-salt-and-how-to-geophysics)を参考にコードを書くことにした\r\n",
        "  - 塩領域の分類をUnetというアルゴリズムを用いて実現している\r\n",
        "  - kerasを用いてUnetを実装している"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5BITAOL2E3C"
      },
      "source": [
        "# 第5話 Unetとは?\r\n",
        "\r\n",
        "- セマンティックセグメンテーションのアルゴリズムの一つ\r\n",
        "- \r\n",
        "- セマンティックセグメンテーションとは画像に写っている物体をピクセルレベルで識別する技術  \r\n",
        "セマンティックセグメンテーションの例  \r\n",
        "![](https://raw.githubusercontent.com/open-mmlab/mmdetection/master/resources/coco_test_12510.jpg)\r\n",
        "\r\n",
        "- Unetのアーキテクチャー\r\n",
        "\r\n",
        "![](https://www.acceluniverse.com/blog/developers/u_net_arc2.png)\r\n",
        "\r\n",
        "- 特徴\r\n",
        "  - 学習が速い\r\n",
        "  - 少ないデータで学習ができる"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGmj75VazUq5"
      },
      "source": [
        "#第3話 境界線を予測するモデルを作る→失敗\r\n",
        "\r\n",
        "- Unetのモデルを入力画像を海岸の画像、出力画像を海岸線の画像として学習させた  \r\n",
        "↓   \r\n",
        "##失敗\r\n",
        "\r\n",
        "![](https://i.imgur.com/gyZwaQ4.png)\r\n",
        "\r\n",
        "\r\n",
        "- 理由\r\n",
        "  - 正解ラベルの数が少なすぎて、適切にモデルをとレーニングができなかったため。"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwq0Xt7FrP1l"
      },
      "source": [
        "# 第5話セマンティックセグメンテーション用にラベルを付けなおして再学習！\r\n",
        "\r\n",
        "- 手動でマスク画像を作成し直す\r\n",
        "- 画像サイズは128*128\r\n",
        "\r\n",
        "![](https://i.imgur.com/ZmIyFLQ.png)\r\n",
        "\r\n",
        "![Uploading file..._gptip3pzt]()\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-bP-xKRxAs9C"
      },
      "source": [
        "#第6話データを拡張してみる\r\n",
        "- 欠損データに対応するためにデータの拡張により疑似的にデータが欠損した部分を作成する。\r\n",
        "\r\n",
        "![](https://i.imgur.com/KH7KPjz.png)\r\n",
        "\r\n",
        "![](https://i.imgur.com/55Va3DS.png)\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Dcq-bHxBE87"
      },
      "source": [
        "# 第7話 入力サイズを大きくする\r\n",
        "- 入力画像サイズを128＊128から512＊512とした\r\n",
        "\r\n",
        "![](https://i.imgur.com/152bh0w.png)\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IC3lJNJrBZxV"
      },
      "source": [
        "#最終話　結果\r\n",
        "###シェイクアップ!!\r\n",
        "- 暫定スコア 30  \r\n",
        "↓\r\n",
        "- 最終スコア 18  \r\n",
        "\r\n",
        "#結果22位となった！"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTaq2H5T3lPo"
      },
      "source": [
        "# ハンズオン\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7VEmHyJ5IbE"
      },
      "source": [
        "#@title 前処理\r\n",
        "im_width = 512\r\n",
        "im_height = 512\r\n",
        "im_chan = 1\r\n",
        "train_ids = [1,2]\r\n",
        "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\r\n",
        "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\r\n",
        "print('Getting and resizing train images and masks ... ')\r\n",
        "sys.stdout.flush()\r\n",
        "\r\n",
        "sizes_train = []\r\n",
        "for n,id_ in enumerate(train_ids):\r\n",
        "    img = load_img(f'/content/The-4th-Tellus-Satellite-Challenge/data/train_gray_{id_:02d}.png')\r\n",
        "    x = img_to_array(img)[:,:,1]\r\n",
        "    sizes_train.append([x.shape[0], x.shape[1]])\r\n",
        "    x = resize(x, (im_height, im_width, 1), mode='constant', preserve_range=True)\r\n",
        "    X_train[n] = x\r\n",
        "    mask = img_to_array(load_img(f'/content/The-4th-Tellus-Satellite-Challenge/data/train_mask_{id_:02d}.png'))[:,:,1]\r\n",
        "    mask = np.where(mask==255,0,255)\r\n",
        "    Y_train[n] = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVo2tzOHlcWH"
      },
      "source": [
        "#@title データの拡張\r\n",
        "data_gen_args  =dict(featurewise_center=False, \r\n",
        "                             samplewise_center=False, \r\n",
        "                             featurewise_std_normalization=False,\r\n",
        "                             samplewise_std_normalization=False, \r\n",
        "                             zca_whitening=False, \r\n",
        "                             zca_epsilon=1e-06, \r\n",
        "                             rotation_range=90, \r\n",
        "                             width_shift_range=0.1, \r\n",
        "                             height_shift_range=0.1,\r\n",
        "                             brightness_range=None,\r\n",
        "                             shear_range=90, zoom_range=0.0,\r\n",
        "                             channel_shift_range=0.0,\r\n",
        "                             fill_mode='constant', cval=0.0,\r\n",
        "                             horizontal_flip=True, \r\n",
        "                             vertical_flip=True, \r\n",
        "                             rescale=None, \r\n",
        "                             preprocessing_function=None, \r\n",
        "                             data_format=None,\r\n",
        "                             validation_split=0.0)\r\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\r\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\r\n",
        "seed = 1\r\n",
        "image_datagen.fit(X_train, augment=True, seed=seed)\r\n",
        "mask_datagen.fit(Y_train, augment=True, seed=seed)\r\n",
        "image_generator = image_datagen.flow(X_train[:17], y=None, batch_size=32, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\r\n",
        "mask_generator = mask_datagen.flow(Y_train[:17], y=None, batch_size=32, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\r\n",
        "train_generator = zip(image_generator, mask_generator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "UuwekTAc5T5K"
      },
      "source": [
        "#@title モデル\r\n",
        "# Define IoU metric\r\n",
        "def mean_iou(y_true, y_pred):\r\n",
        "    prec = []\r\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\r\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\r\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\r\n",
        "        K.get_session().run(tf.local_variables_initializer())\r\n",
        "        with tf.control_dependencies([up_opt]):\r\n",
        "            score = tf.identity(score)\r\n",
        "        prec.append(score)\r\n",
        "    return K.mean(K.stack(prec), axis=0)\r\n",
        "# Build U-Net model\r\n",
        "inputs = Input((im_height, im_width, im_chan))\r\n",
        "s = Lambda(lambda x: x / 255) (inputs)\r\n",
        "\r\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\r\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\r\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\r\n",
        "\r\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\r\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\r\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\r\n",
        "\r\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\r\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\r\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\r\n",
        "\r\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\r\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\r\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\r\n",
        "\r\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\r\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\r\n",
        "\r\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\r\n",
        "u6 = concatenate([u6, c4])\r\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\r\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\r\n",
        "\r\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\r\n",
        "u7 = concatenate([u7, c3])\r\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\r\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\r\n",
        "\r\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\r\n",
        "u8 = concatenate([u8, c2])\r\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\r\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\r\n",
        "\r\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\r\n",
        "u9 = concatenate([u9, c1], axis=3)\r\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\r\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\r\n",
        "\r\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\r\n",
        "\r\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\r\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zMTkHa3c5dQG"
      },
      "source": [
        "#title 学習\r\n",
        "import keras\r\n",
        "model = load_model('/content/The-4th-Tellus-Satellite-Challenge/34.h5', custom_objects={'mean_iou': mean_iou})\r\n",
        "class nvidia(keras.callbacks.Callback):\r\n",
        "    def on_batch_end(self, batch, logs={}):\r\n",
        "        !nvidia-smi\r\n",
        "earlystopper = EarlyStopping(patience=500, verbose=1)\r\n",
        "nvidiaCallback = nvidia()\r\n",
        "checkpointer = ModelCheckpoint('/content/model-tgs-salt-1.h5', verbose=1, save_best_only=True,monitor='val_mean_iou', mode='max')\r\n",
        "results = model.fit_generator(train_generator, validation_data=(X_train,Y_train), steps_per_epoch=300, epochs=300,\r\n",
        "                    callbacks=[earlystopper, checkpointer],shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zE9Dqm1I6N1b"
      },
      "source": [
        "#@title 予測\r\n",
        "model = load_model('/content/The-4th-Tellus-Satellite-Challenge/34.h5', custom_objects={'mean_iou': mean_iou})\r\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0])], verbose=1)\r\n",
        "\r\n",
        "# Threshold predictions\r\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lp3Ay80K6SAB"
      },
      "source": [
        "# 予測結果の確認\r\n",
        "plt.imshow(np.squeeze(preds_train_t[0]))\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}