{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "satelite_model",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1bMplSFH-98nBKqHOG44EH42-gVJZSMi3",
      "authorship_tag": "ABX9TyMOq2pnAkLh1mnsEb5XwgFP",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ydaigo/The-4th-Tellus-Satellite-Challenge/blob/main/satelite_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9grv2Y8QL4L",
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 61
        },
        "outputId": "e9d020f1-2f99-4b4b-b6b3-8b77a4580900"
      },
      "source": [
        "#@title 準備\n",
        "!pip uninstall tensorflow -y\n",
        "!pip install tensorflow-gpu==1.15\n",
        "!pip uninstall keras -y\n",
        "!pip install keras==2.2.4\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import warnings\n",
        "import json\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "import cv2\n",
        "import tifffile\n",
        "from tqdm import tqdm_notebook, tnrange\n",
        "from itertools import chain\n",
        "from skimage.io import imread, imshow, concatenate_images\n",
        "from skimage.transform import resize\n",
        "from skimage.morphology import label\n",
        "\n",
        "from keras.models import Model, load_model\n",
        "from keras.layers import Input\n",
        "from keras.layers.core import Lambda\n",
        "from keras.layers.convolutional import Conv2D, Conv2DTranspose\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras.layers.merge import concatenate\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from keras import backend as K\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "\n",
        "# 接続切れ対策\n",
        "import IPython\n",
        "from google.colab import output\n",
        "\n",
        "display(IPython.display.Javascript('''\n",
        " function ClickConnect(){\n",
        "   btn = document.querySelector(\"colab-connect-button\")\n",
        "   if (btn != null){\n",
        "     console.log(\"Click colab-connect-button\"); \n",
        "     btn.click() \n",
        "     }\n",
        "   \n",
        "   btn = document.getElementById('ok')\n",
        "   if (btn != null){\n",
        "     console.log(\"Click reconnect\"); \n",
        "     btn.click() \n",
        "     }\n",
        "  }\n",
        "  \n",
        "setInterval(ClickConnect,60000)\n",
        "'''))\n",
        "\n",
        "print(\"Done.\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Uninstalling tensorflow-2.3.0:\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jce1QcwtWuFf",
        "collapsed": true
      },
      "source": [
        "#@title 前処理\n",
        "im_width = 512\n",
        "im_height = 512\n",
        "im_chan = 1\n",
        "train_ids = [1,2,3,4,5,6,7,11,13,14,15,16,17,18,19,21,22,23,24]\n",
        "test_ids = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19\n",
        "            ,20,21,22,23,24,25,26,27,28,29]\n",
        "X_train = np.zeros((len(train_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "Y_train = np.zeros((len(train_ids), im_height, im_width, 1), dtype=np.bool)\n",
        "X_test = np.zeros((len(test_ids), im_height, im_width, im_chan), dtype=np.uint8)\n",
        "print('Getting and resizing train images and masks ... ')\n",
        "sys.stdout.flush()\n",
        "\n",
        "sizes_train = []\n",
        "for n,id_ in enumerate(train_ids):\n",
        "    img = load_img(f'/content/drive/My Drive/signate/satelite/train_images_png_full/train_gray_{id_:02d}.png')\n",
        "    x = img_to_array(img)[:,:,1]\n",
        "    sizes_train.append([x.shape[0], x.shape[1]])\n",
        "    x = resize(x, (im_height, im_width, 1), mode='constant', preserve_range=True)\n",
        "    X_train[n] = x\n",
        "    mask = img_to_array(load_img(f'/content/drive/My Drive/signate/satelite/mask_full_v2/train_mask_{id_:02d}.png'))[:,:,1]\n",
        "    mask = np.where(mask==255,0,255)\n",
        "    Y_train[n] = resize(mask, (im_width, im_height, 1), mode='constant', preserve_range=True)\n",
        "sizes_test = []\n",
        "for n, id_ in enumerate(test_ids):\n",
        "    img = load_img(f'/content/drive/My Drive/signate/satelite/test_images_png_full/test_gray_{id_:02d}.png')\n",
        "    x = img_to_array(img)[:,:,1]\n",
        "    sizes_test.append([x.shape[0], x.shape[1]])\n",
        "    x = resize(x, (im_height, im_width, 1), mode='constant', preserve_range=True)\n",
        "    X_test[n] = x\n",
        "\n",
        "print('Done!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EEgAeNlQep_0"
      },
      "source": [
        "# generator\n",
        "data_gen_args  =dict(featurewise_center=False, \n",
        "                             samplewise_center=False, \n",
        "                             featurewise_std_normalization=False,\n",
        "                             samplewise_std_normalization=False, \n",
        "                             zca_whitening=False, \n",
        "                             zca_epsilon=1e-06, \n",
        "                             rotation_range=90, \n",
        "                             width_shift_range=0.1, \n",
        "                             height_shift_range=0.1,\n",
        "                             brightness_range=None,\n",
        "                             shear_range=90, zoom_range=0.0,\n",
        "                             channel_shift_range=0.0,\n",
        "                             fill_mode='constant', cval=0.0,\n",
        "                             horizontal_flip=True, \n",
        "                             vertical_flip=True, \n",
        "                             rescale=None, \n",
        "                             preprocessing_function=None, \n",
        "                             data_format=None,\n",
        "                             validation_split=0.0)\n",
        "image_datagen = ImageDataGenerator(**data_gen_args)\n",
        "mask_datagen = ImageDataGenerator(**data_gen_args)\n",
        "seed = 1\n",
        "image_datagen.fit(X_train[:17], augment=True, seed=seed)\n",
        "mask_datagen.fit(Y_train[:17], augment=True, seed=seed)\n",
        "image_generator = image_datagen.flow(X_train[:17], y=None, batch_size=16, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\n",
        "mask_generator = mask_datagen.flow(Y_train[:17], y=None, batch_size=16, shuffle=False, seed=0, save_to_dir=None, save_prefix='', save_format='png', subset=None)\n",
        "train_generator = zip(image_generator, mask_generator)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPDRrIoxXZSV",
        "collapsed": true
      },
      "source": [
        "#@title モデル\n",
        "# Define IoU metric\n",
        "def mean_iou(y_true, y_pred):\n",
        "    prec = []\n",
        "    for t in np.arange(0.5, 1.0, 0.05):\n",
        "        y_pred_ = tf.to_int32(y_pred > t)\n",
        "        score, up_opt = tf.metrics.mean_iou(y_true, y_pred_, 2)\n",
        "        K.get_session().run(tf.local_variables_initializer())\n",
        "        with tf.control_dependencies([up_opt]):\n",
        "            score = tf.identity(score)\n",
        "        prec.append(score)\n",
        "    return K.mean(K.stack(prec), axis=0)\n",
        "# Build U-Net model\n",
        "inputs = Input((im_height, im_width, im_chan))\n",
        "s = Lambda(lambda x: x / 255) (inputs)\n",
        "\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (s)\n",
        "c1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\n",
        "p1 = MaxPooling2D((2, 2)) (c1)\n",
        "\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\n",
        "c2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\n",
        "p2 = MaxPooling2D((2, 2)) (c2)\n",
        "\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\n",
        "c3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\n",
        "p3 = MaxPooling2D((2, 2)) (c3)\n",
        "\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\n",
        "c4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n",
        "p4 = MaxPooling2D(pool_size=(2, 2)) (c4)\n",
        "\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (p4)\n",
        "c5 = Conv2D(128, (3, 3), activation='relu', padding='same') (c5)\n",
        "\n",
        "u6 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c5)\n",
        "u6 = concatenate([u6, c4])\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (u6)\n",
        "c6 = Conv2D(64, (3, 3), activation='relu', padding='same') (c6)\n",
        "\n",
        "u7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\n",
        "u7 = concatenate([u7, c3])\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (u7)\n",
        "c7 = Conv2D(32, (3, 3), activation='relu', padding='same') (c7)\n",
        "\n",
        "u8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\n",
        "u8 = concatenate([u8, c2])\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (u8)\n",
        "c8 = Conv2D(16, (3, 3), activation='relu', padding='same') (c8)\n",
        "\n",
        "u9 = Conv2DTranspose(8, (2, 2), strides=(2, 2), padding='same') (c8)\n",
        "u9 = concatenate([u9, c1], axis=3)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (u9)\n",
        "c9 = Conv2D(8, (3, 3), activation='relu', padding='same') (c9)\n",
        "\n",
        "outputs = Conv2D(1, (1, 1), activation='sigmoid') (c9)\n",
        "\n",
        "model = Model(inputs=[inputs], outputs=[outputs])\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[mean_iou])\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9RnhyetXdyO",
        "collapsed": true,
        "cellView": "both"
      },
      "source": [
        "#title 学習\n",
        "import keras\n",
        "model = load_model('/content/drive/My Drive/signate/satelite/weight/checkpoint/30.h5', custom_objects={'mean_iou': mean_iou})\n",
        "class nvidia(keras.callbacks.Callback):\n",
        "    def on_batch_end(self, batch, logs={}):\n",
        "        !nvidia-smi\n",
        "earlystopper = EarlyStopping(patience=500, verbose=1)\n",
        "nvidiaCallback = nvidia()\n",
        "checkpointer = ModelCheckpoint('/content/drive/My Drive/signate/satelite/weight/checkpoint/model-tgs-salt-1.h5', verbose=1, save_best_only=True,monitor='val_mean_iou', mode='max')\n",
        "results = model.fit_generator(train_generator, validation_data=(X_train[17:],Y_train[17:]), steps_per_epoch=300, epochs=300,\n",
        "                    callbacks=[earlystopper, checkpointer],shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GAjExID2XqbW"
      },
      "source": [
        "#@title 予測\n",
        "model = load_model('/content/drive/My Drive/signate/satelite/weight/checkpoint/model-tgs-salt-1.h5', custom_objects={'mean_iou': mean_iou})\n",
        "preds_train = model.predict(X_train[:int(X_train.shape[0]*0.9)], verbose=1)\n",
        "preds_val = model.predict(X_train[int(X_train.shape[0]*0.9):], verbose=1)\n",
        "preds_test = model.predict(X_test, verbose=1)\n",
        "\n",
        "# Threshold predictions\n",
        "preds_train_t = (preds_train > 0.5).astype(np.uint8)\n",
        "preds_val_t = (preds_val > 0.5).astype(np.uint8)\n",
        "preds_test_t = (preds_test > 0.5).astype(np.uint8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_JW4r8H8kXE"
      },
      "source": [
        "#@title 可視化\n",
        "for i in range(len(preds_test_t)):\n",
        "  plt.imshow(np.squeeze(X_test[i]))\n",
        "  plt.colorbar()\n",
        "  plt.show()\n",
        "  plt.imshow(np.squeeze(preds_test_t[i]))\n",
        "  plt.show()\n",
        "  img = np.squeeze(preds_test_t[i]).astype(np.float64)\n",
        "  img = np.round(cv2.resize(img,(sizes_test[i][1],sizes_test[i][0])))\n",
        "  # u, counts = np.unique(img, return_counts=True)\n",
        "  # print(u)\n",
        "  # # [ 0 10 20 30]\n",
        "\n",
        "  # print(counts)\n",
        "  #img = resize(img, (sizes_test[0][0], sizes_test[0][1]), mode='constant', preserve_range=True)\n",
        "  #contours,hierarchy = cv2.findContours(img, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "  kernel_x = np.array([[0,0,0],\n",
        "                    [0,1,-1],\n",
        "                    [0,0,0]])\n",
        "  kernel_y = np.array([[0,0,0],\n",
        "                    [0,1,0],\n",
        "                    [0,-1,0]])\n",
        "  img = np.where(cv2.filter2D(img, -1, kernel_x)!=0,1,0)+np.where(cv2.filter2D(img, -1, kernel_y)!=0,1,0)\n",
        "  plt.imshow(img)\n",
        "\n",
        "  plt.show()\n",
        "  print(len(list(zip(*np.where(img!=0)))))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdE9LWWL5cjs"
      },
      "source": [
        "#@title 後処理 ファイルの作成\n",
        "json_ ={}\n",
        "for id_,img in enumerate(preds_test_t):\n",
        "  img =np.squeeze(img).astype(np.float64)\n",
        "  img = np.round(cv2.resize(img,(sizes_test[id_][1],sizes_test[id_][0]),interpolation=cv2.INTER_NEAREST))\n",
        "  kernel_x = np.array([[0,0,0],\n",
        "                    [0,1,-1],\n",
        "                    [0,0,0]])\n",
        "  kernel_y = np.array([[0,0,0],\n",
        "                    [0,1,0],\n",
        "                    [0,-1,0]])\n",
        "  img = np.where(cv2.filter2D(img, -1, kernel_x)!=0,1,0)+np.where(cv2.filter2D(img, -1, kernel_y)!=0,1,0)\n",
        "  #print(sizes_test[id_])\n",
        "  #print(np.unique(img))\n",
        "  #border = list(zip(*np.where(img!=0)))\n",
        "  print(len(list(zip(*np.where(img>0)))))\n",
        "  if len(list(zip(*np.where(img>0))))<29000:\n",
        "    json_[f'test_{id_:02d}.tif'] = [[int(j),int(i)] for i,j in zip(*np.where((img!=0)))]\n",
        "  else:\n",
        "    json_[f'test_{id_:02d}.tif'] = [[0,0]]\n",
        "with open(\"/content/submit.json\", \"w\") as f:\n",
        "    json.dump(json_, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EC9rR57u-Z2g"
      },
      "source": [
        "json_[f'test_26.tif']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pTQ5qF-zKkS"
      },
      "source": [
        "json_ ={}\n",
        "for id_,img in enumerate(Y_train[:1]):\n",
        "  img =np.squeeze(img).astype(np.float64)\n",
        "  img = cv2.resize(img,(sizes_train[id_][1],sizes_train[id_][0]),interpolation=cv2.INTER_NEAREST)\n",
        "  print(np.unique(img))\n",
        "  kernel_x = np.array([[0,0,0],\n",
        "                    [0,1,-1],\n",
        "                    [0,0,0]])\n",
        "  kernel_y = np.array([[0,0,0],\n",
        "                    [0,1,0],\n",
        "                    [0,-1,0]])\n",
        "  img = np.where(cv2.filter2D(img, -1, kernel_x)!=0,1,0)+np.where(cv2.filter2D(img, -1, kernel_y)!=0,1,0)\n",
        "  #print(sizes_test[id_])\n",
        "  print(np.unique(img))\n",
        "  #border = list(zip(*np.where(img!=0)))\n",
        "  print(len(list(zip(*np.where(img>0)))))\n",
        "  id_ = 2\n",
        "  json_[f'train_{id_:02d}.tif'] = [[int(j),int(i)] for i,j in zip(*np.where((img!=0)))]\n",
        "with open(\"/content/train.json\", \"w\") as f:\n",
        "    json.dump(json_, f)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_VEKq8abNvr"
      },
      "source": [
        "img =np.squeeze(Y_train[0]).astype(np.float64)\n",
        "img = cv2.resize(img,(sizes_train[id_][1],sizes_train[id_][0]),interpolation=cv2.INTER_NEAREST)\n",
        "kernel_x = np.array([[0,0,0],\n",
        "                  [0,1,-1],\n",
        "                  [0,0,0]])\n",
        "kernel_y = np.array([[0,0,0],\n",
        "                  [0,1,0],\n",
        "                  [0,-1,0]])\n",
        "img = np.where(cv2.filter2D(img, -1, kernel_x)!=0,1,0)+np.where(cv2.filter2D(img, -1, kernel_y)!=0,1,0)\n",
        "plt.imshow(np.squeeze(img))\n",
        "np.unique(img)\n",
        "cv2.imwrite('a.png', img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SO_pv7fPgvIA"
      },
      "source": [
        "img = np.array([[0,0,0,0,0],\n",
        "                [0,0,0,0,0],\n",
        "                [1,1,1,1,1],\n",
        "                [0,0,0,0,0],\n",
        "                [0,0,0,0,0]]).astype(np.float32)\n",
        "img = cv2.resize(img,(100,100),interpolation  = cv2.INTER_LINEAR)\n",
        "plt.imshow(img)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SbVFPbLpccj_"
      },
      "source": [
        "Y_train[0].dtype"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nu5e7RkIbc5A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORf24jbbKOZz"
      },
      "source": [
        "#　評価\n",
        "img = img_to_array(load_img(f'/content/train_mask_02.png'))[:,:,1]\n",
        "img = cv2.resize(img,(128,128),interpolation=cv2.INTER_NEAREST)\n",
        "img = cv2.resize(img,(sizes_train[0][1],sizes_train[0][0]),interpolation=cv2.INTER_NEAREST)\n",
        "print(np.unique(img))\n",
        "kernel_x = np.array([[0,0,0],\n",
        "                  [0,1,-1],\n",
        "                  [0,0,0]])\n",
        "kernel_y = np.array([[0,0,0],\n",
        "                  [0,1,0],\n",
        "                  [0,-1,0]])\n",
        "img = np.where(cv2.filter2D(img, -1, kernel_x)!=0,1,0)+np.where(cv2.filter2D(img, -1, kernel_y)!=0,1,0)\n",
        "id_ = 2\n",
        "json_[f'train_{id_:02d}.tif'] = [[int(j),int(i)] for i,j in zip(*np.where((img!=0)))]\n",
        "with open(\"/content/train.json\", \"w\") as f:\n",
        "    json.dump(json_, f)\n",
        "with open('/content/drive/My Drive/signate/satelite/train_annotations/train_02.json') as f:\n",
        "    df = json.load(f)\n",
        "aa = {}\n",
        "aa[\"train_02.tif\"] = df\n",
        "with open(\"/content/ano.json\", \"w\") as f:\n",
        "    json.dump(aa, f)\n",
        "!python /content/drive/My\\ Drive/signate/satelite/evaluate.py \\\n",
        "  --prediction-file /content/train.json \\\n",
        "  --annotation-file /content/ano.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7opa7aDFsIYY"
      },
      "source": [
        "mask = img_to_array(load_img(f'/content/train_mask_02.png'))[:,:,1]\n",
        "mask.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSjuQFA11vxK"
      },
      "source": [
        "json_"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}